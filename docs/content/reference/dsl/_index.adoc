---
layout: header
header: "lexy/dsl.hpp"
umbrella: true
menu:
  main:
    name: "DSL"
    weight: 3
---

[.lead]
The rule DSL for specifying the grammar.

The grammar in lexy is specified in several productions, where each one defines an associated _rule_.
This rule is an object built from the objects and functions of namespace `lexy::dsl` that defines some (implementation-defined) parsing function.
Parsing a rule takes the reader, which remembers the current position of the input, and the context, which stores information about the current production and whitespace rules, and is responsible for handling errors and values;
it can have one of the following results:

* Parsing can succeed.
  Then it consumes some input by advancing the reader position and produces zero or more values.
* Parsing can fail.
  Then it reports an error, potentially after having consumed some input but without producing values.
  The parent rule can react to the failure by recovering from it or they fail itself.
* Parsing can fail, but then recover.
  Then it has reported an error, but now it has consumed enough input to be in a known good state and parsing continues normally.
  See {{% docref "error recovery" %}} for details.

A {{% branch-rule %}} is a special kind of rule that has an easy to check condition.
They are used to guide decisions in the parsing algorithm.
Every branch rule defines some (implementation defined) branch parsing function.
It mostly behaves the same as the normal parse rule, but can have one additional result:
branch parsing can _backtrack_.
If it backtracks, it hasn't consumed any input, raised errors or produced values.
The parsing algorithm is then free to try another branch.

NOTE: The idea is that a branch rule can relatively quickly decide whether or not it should backtrack.
If a branch rule does not backtrack, but fails instead, this failure is propagated and the parsing algorithm does not try another branch.

A {{% token-rule %}} is a special kind of rule that describes the atomic elements.
Parsing them never produces any values and can happen easily,
as such they're also branch rules where the entire rule is used as the condition.
Because they're atomic elements of the input, they also participate in {{% docref "whitespace" "automatic whitespace skipping" %}}:
after every token, lexy will automatically skip whitespace, if one has been defined.

== How to read the DSL documentation footnote:[link:https://xkcd.com/1343[obligatory XKCD]]

The behavior of a rule is described by the following sections.

Matching/parsing::
  This section describes what input is matched for the rule to succeed, and what is consumed.
  For token rules it is called "matching", otherwise "parsing".
+
It often delegates to the behavior of other rules:
Here, the term "parsing" refers to the parsing operation of a rule,
"branch parsing" or "try to parse" refers to the special parsing operation of a branch rule, which can backtrack,
"matching" refers to the parsing operation of a token rule, which cannot produce values,
and "try matching" refers to the branch parsing operation of a token rule, which cannot produce values or raise errors.
Branch parsing::
  This section describes what input is matched, consumed, and leads to a backtracking for a branch rule.
  Note that a rule can parse something different here than during non-branch parsing.
Errors::
  This section describes what errors are raised, when, and where.
  It also describes whether the rule can recover after the error.
Values::
  This section describes what values are produced during a successful parsing operation.
  It is omitted for token rules, which never produce values.
Parse tree::
  This section describes what nodes are created in the `lexy::parse_tree`.
  If omitted, a token rule creates a single token node covering everything consumed,
  and a rule produces no extra nodes besides the ones created by the other rules it parses.

== The rule DSL

[%collapsible]
.Primitive tokens
====
{{% docref "lexy::dsl::lit" %}} and {{% docref "lexy::dsl::lit_c" %}}::
  match character sequences
{{% docref "lexy::dsl::any" %}}::
  match anything
{{% docref "lexy::dsl::eof" %}}::
  match EOF
{{% docref "lexy::dsl::newline" %}} and {{% docref "lexy::dsl::eol" %}}::
  match the end of a line
{{% docref "lexy::dsl::token" %}}::
  turn a rule into a token
====

[%collapsible]
.Character classes
====
{{% docref "lexy::dsl::ascii" %}}::
  match ASCII character classes
{{% docref "lexy::dsl::code_point" %}}::
  match Unicode code points
{{% docref "lexy::dsl::operator-" %}}::
  exclude some characters
{{% docref "lexy::dsl::operator/" %}}::
  combine character classes
====

[%collapsible]
.Branch conditions
====
{{% docref "lexy::dsl::operator>>" %}}::
  add a branch condition to a rule
{{% docref "lexy::dsl::else_" %}}::
  branch condition that is always taken
{{% docref "lexy::dsl::peek" %}} and {{% docref "lexy::dsl::peek_not" %}}::
  check whether something matches without consuming it
{{% docref "lexy::dsl::lookahead" %}}::
  check whether something matches somewhere in the input without consuming it
====

[%collapsible]
.Combinators
=====
{{% docref "lexy::dsl::operator+" %}}::
  parse a sequence of rules
{{% docref "lexy::dsl::operator|" %}}::
  parse one of the specified (branch) rules
{{% docref "lexy::dsl::combination" %}} and {{% docref "lexy::dsl::partial_combination" %}}::
  parse all (some) of the (branch) rules in arbitrary order
{{% docref "lexy::dsl::if_" %}} and {{% docref "lexy::dsl::opt" %}}::
  parse a branch rule if its condition matches
{{% docref "lexy::dsl::loop" %}}::
  parse a rule repeatedly
{{% docref "lexy::dsl::while_" %}} and {{% docref "lexy::dsl::while_one" %}}::
  parse a branch rule while its condition matches
{{% docref "lexy::dsl::times" %}}::
  parse a rule N times
{{% docref "lexy::dsl::list" %}}::
  parse a list of things
{{% docref "lexy::dsl::until" %}}::
  skip everything until a rule matches
=====


[%collapsible]
.Brackets and delimited
=====
{{% docref "lexy::dsl::terminator" %}}::
  parse something that ends with a terminator
{{% docref "lexy::dsl::brackets" %}}::
  parse something surrounded by brackets
{{% docref "lexy::dsl::delimited" %}} and {{% docref "lexy::dsl::escape" %}}::
  parse everything between two delimiters, with optional escape sequences
=====

[%collapsible]
.Productions
====
{{% docref "lexy::dsl::p" %}} and {{% docref "lexy::dsl::recurse" %}}::
  parse another production
{{% docref "lexy::dsl::inline_" %}}::
  parse another production's rule inline
{{% docref "lexy::dsl::return_" %}}::
  exit early from parsing a production
====

[%collapsible]
.Values
=====
{{% docref "lexy::dsl::capture" %}}::
  capture everything consumed by a rule
{{% docref "lexy::dsl::position" %}}::
  produce the current input position
{{% docref "lexy::dsl::nullopt" %}}::
  produce an empty placeholder value
{{% docref "lexy::dsl::member" %}}::
  parse something into a member variable
=====

[%collapsible]
.Errors and error recovery
=====
{{% docref "lexy::dsl::error" %}}::
  explicitly raise an error
{{% docref "lexy::dsl::prevent" %}} and {{% docref "lexy::dsl::require" %}}::
  perform lookahead and raise an error on failure
{{% docref "lexy::dsl::try_" %}}::
  recover from a failed rule
{{% docref "lexy::dsl::recover" %}}::
  recover by looking and then continuing with some other rule
{{% docref "lexy::dsl::find" %}}::
  recover by looking for synchronization tokens
=====

[%collapsible]
.Whitespace
====
{{% docref "lexy::dsl::whitespace" %}}::
  explicitly skip whitespace
{{% docref "lexy::dsl::no_whitespace" %}}::
  do not skip whitespace
====

[%collapsible]
.Identifiers
====
{{% docref "lexy::dsl::identifier" %}}::
  parse an identifier
{{% docref "lexy::dsl::keyword" %}}::
  parse a keyword
{{% docref "lexy::dsl::symbol" %}}::
  parse one of the specified symbols and produce their value
====

[%collapsible]
.Numbers
====
{{% docref "lexy::dsl::zero" %}}::
  parse zero
{{% docref "lexy::dsl::digit" %}}::
  parse a digit
{{% docref "lexy::dsl::digits" %}}::
  parse one or more digits
{{% docref "lexy::dsl::n_digits" %}}::
  parse N digits
{{% docref "lexy::dsl::integer" %}}::
  convert digits to an integer
{{% docref "lexy::dsl::sign" %}}, {{% docref "lexy::dsl::plus_sign" %}} and {{% docref "lexy::dsl::minus_sign" %}}::
  parse a sign
{{% docref "lexy::dsl::code_point_id" %}}::
  convert N digits into a code point
====

[%collapsible]
.Context-sensitive parsing
====
{{% docref "lexy::dsl::context_flag" %}}::
  a boolean flag
{{% docref "lexy::dsl::context_counter" %}}::
  an integer counter
{{% docref "lexy::dsl::context_lexeme" %}}::
  a string variable
====

[%collapsible]
.Input specific rules
====
{{% docref "lexy::dsl::bom" %}} and {{% docref "lexy::dsl::encode" %}}::
  interpret bytes as text
{{% docref "lexy::dsl::argv_separator" %}}::
  match the argument separator of a `lexy::argv_input`
====

